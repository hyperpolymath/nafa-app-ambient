// SPDX-License-Identifier: MIT OR AGPL-3.0-or-later
// SPDX-FileCopyrightText: 2025 hyperpolymath

= NAFA – Neurodiverse App for Adventurers

image:https://img.shields.io/badge/license-AGPL--3.0-blue.svg[AGPL-3.0,link="https://www.gnu.org/licenses/agpl-3.0"] image:https://img.shields.io/badge/philosophy-Palimpsest-purple.svg[Palimpsest,link="https://github.com/hyperpolymath/palimpsest-licence"]
:toc: left
:toclevels: 3
:icons: font

== Vision

NAFA is a journey planning app designed to help neurodiverse adventurers navigate public transport and sensory-rich environments with calm, confidence, and symbolic clarity.

We encode sensory awareness, accessibility preferences, and offline resilience into every module—making NAFA not just a tool, but a companion.

== Tech Stack

[cols="1,3", options="header"]
|===
|Layer |Technology

|*Runtime*
|Deno – secure, modern JavaScript/TypeScript runtime

|*Client Logic*
|ReScript – type-safe, compiles to clean JavaScript, TEA pattern

|*Server*
|Deno HTTP – REST API with JSON responses

|*Mobile*
|Tauri 2.0 – Rust backend + web UI (iOS/Android)

|*Desktop*
|Tauri 2.0 – native performance, no Electron bloat

|*Configuration*
|Nickel – typed configuration language for badge logic

|*Routing Data*
|GraphHopper + OpenStreetMap (planned)
|===

=== Language Policy

Following the https://hyperpolymath.org[Hyperpolymath Standard]:

[cols="1,1", options="header"]
|===
|Allowed |Banned

|ReScript, Rust, Deno, Gleam
|TypeScript, Node.js, npm, Go

|JavaScript (Deno APIs only)
|Python (except SaltStack)

|Tauri 2.0, Dioxus (mobile)
|Kotlin, Swift, React Native, Flutter
|===

== Features

=== MVP (Complete)

* *Journey Planning* – Sensory-aware route segments with warnings
* *Sensory Annotations* – Crowdsourced location data (noise/light/crowd levels)
* *Accessibility Settings* – Text size, contrast, motion, haptics, screen reader support
* *Offline Mode* – Cached journeys, sync status, works without internet

=== Planned

* Real-time routing integration
* Tauri mobile apps (iOS/Android)
* Haptic feedback via Rust/Tauri plugins
* AR overlays for calm zone detection
* Biometric sensing via wearable integration

== Project Structure

[source]
----
nafa-app-ambient/
├── client/                    # ReScript SPA (TEA pattern)
│   ├── src/
│   │   ├── Main.res          # App entry point
│   │   └── Page/
│   │       ├── JourneyView.res
│   │       ├── Annotate.res
│   │       ├── Accessibility.res
│   │       └── Offline.res
│   └── rescript.json
│
├── server/                    # Deno HTTP server
│   ├── src/
│   │   ├── main.js           # REST API
│   │   └── demo.js           # CLI demo
│   └── deno.json
│
├── shared/                    # Shared domain types
│   ├── src/
│   │   ├── Domain.res        # Core types
│   │   └── Route.res         # Type-safe routing
│   └── rescript.json
│
├── nickel-rituals/            # Badge/tier configuration
│   ├── badge.ncl
│   └── tier.ncl
│
├── scripts/                   # Build automation
├── Justfile                   # Task runner
├── Containerfile              # Deno container build
└── PLAN.adoc                  # Migration roadmap
----

== Quick Start

[source,bash]
----
# Run the CLI demo (shows all features)
just mvp-demo

# Start the API server
just mvp-server

# Development mode with watch
just mvp-dev
----

=== Requirements

* https://deno.land[Deno] 2.1+
* https://just.systems[just] (task runner)

== Mobile Strategy

NAFA uses *Rust-first mobile development* via:

=== Tauri 2.0

* Web UI (ReScript) + Rust backend
* Single codebase for iOS, Android, desktop
* Native performance, minimal bundle size
* MIT/Apache-2.0 licensed, no Big Tech dependencies

=== Dioxus (Alternative)

* Pure Rust with React-like syntax
* Native UI components
* WASM support for web

Both approaches avoid Kotlin/Swift entirely, keeping the stack unified around Rust.

== Ambient Extensions

NAFA is designed to interoperate with sensory hardware:

* *Haptic Feedback* – Via Rust/Tauri plugins to device APIs
* *Visual Overlays* – AR glasses integration (future)
* *BLE Beacons* – Calm zone detection
* *Wearables* – Heart rate, stress indicators

All integrations use Rust for the native layer, exposed to the ReScript UI via Tauri commands.

== Contributor Tiers

NAFA uses symbolic badge logic to recognise contributors:

[cols="1,3"]
|===
|Badge |Criteria

|*Initiate*
|First calm journey completed

|*Curator*
|Contributed sensory annotation

|*Guardian*
|Tested emergency fallback features

|*Companion*
|Assisted others in sensory-rich zones
|===

Badge logic is defined in `nickel-rituals/badge.ncl`.

== API Endpoints

[cols="1,1,2", options="header"]
|===
|Method |Path |Description

|GET
|`/api/journey/:id`
|Retrieve journey by ID

|GET
|`/api/annotations`
|List all sensory annotations

|POST
|`/api/annotation`
|Create new annotation
|===

== Development

=== Build Commands

[source,bash]
----
just mvp-demo      # Run CLI demo
just mvp-server    # Start server on :8080
just mvp-dev       # Server with --watch
just mvp-build     # Build ReScript modules
just mvp-check     # Type-check server files
----

=== Container Build

[source,bash]
----
podman build -f Containerfile -t nafa:latest .
podman run -p 8080:8080 nafa:latest
----

== Licensing

NAFA is dual-licensed under:

* *MIT* – For maximum flexibility
* *AGPL-3.0-or-later* – For copyleft protection

All source files include SPDX license headers.

== Links

* Project: https://github.com/hyperpolymath/nafa-app-ambient
* Issues: https://github.com/hyperpolymath/nafa-app-ambient/issues
* Hyperpolymath: https://hyperpolymath.org

== Join the Journey

NAFA is a living project. Every commit, annotation, and accessibility improvement is a step toward calmer, more inclusive travel.

Contributions welcome – see link:CONTRIBUTING.md[CONTRIBUTING.md].
